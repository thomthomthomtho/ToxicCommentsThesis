
TF-IDF VECTORIZER
best max Depth = no limiet
Best vocab size = 5000
only uni & bigrams
Aantal trees = tussen 100 en 300 presteert evengoed soortvan
Best min_samples_leaf=2
Best min_samples_split=20

(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28650
           1       0.72      0.75      0.73      3243

    accuracy                           0.94     31893
   macro avg       0.84      0.86      0.85     31893
weighted avg       0.95      0.94      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28834
           1       0.70      0.74      0.72      3059

    accuracy                           0.95     31893
   macro avg       0.84      0.85      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31608
           1       0.22      0.70      0.33       285

    accuracy                           0.97     31893
   macro avg       0.61      0.84      0.66     31893
weighted avg       0.99      0.97      0.98     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.99     30199
           1       0.70      0.83      0.76      1694

    accuracy                           0.97     31893
   macro avg       0.84      0.90      0.87     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.27      0.44      0.34        95

    accuracy                           0.99     31893
   macro avg       0.64      0.72      0.67     31893
weighted avg       1.00      0.99      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.97      0.98     30324
           1       0.57      0.78      0.66      1569

    accuracy                           0.96     31893
   macro avg       0.78      0.87      0.82     31893
weighted avg       0.97      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31632
           1       0.19      0.57      0.29       261

    accuracy                           0.98     31893
   macro avg       0.60      0.77      0.64     31893
weighted avg       0.99      0.98      0.98     31893


AAAAAAAAADFEAEAFESFESFSEFESFCESFVCSEFSFVRSVSRVRDFVDRVDESGVSGVGSRGSBDFBDRBSVSVSEKJSEJCVAECVUYAWVCLUAECLUHACAHJKECBHJLAEBHJKAEVCLYUAGWVAEKJHWCBKAWBCVKHJAECLHJAEBCLJHAELCKAEHCBAEJHKCB


Countvectorizer
Vocab = 5000
unigrams (no bigrams)
100 trees
min_sample_split = 20
min_sample_leaf = 2
no max depth


Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using CountVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.96      0.97     28650
           1       0.71      0.77      0.74      3243

    accuracy                           0.94     31893
   macro avg       0.84      0.87      0.85     31893
weighted avg       0.95      0.94      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.96      0.97     28834
           1       0.68      0.77      0.72      3059

    accuracy                           0.94     31893
   macro avg       0.83      0.87      0.85     31893
weighted avg       0.95      0.94      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     31608
           1       0.21      0.78      0.33       285

    accuracy                           0.97     31893
   macro avg       0.60      0.88      0.66     31893
weighted avg       0.99      0.97      0.98     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     30199
           1       0.68      0.85      0.75      1694

    accuracy                           0.97     31893
   macro avg       0.83      0.92      0.87     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.99      1.00     31798
           1       0.19      0.52      0.28        95

    accuracy                           0.99     31893
   macro avg       0.59      0.75      0.64     31893
weighted avg       1.00      0.99      0.99     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.97      0.98     30324
           1       0.55      0.80      0.65      1569

    accuracy                           0.96     31893
   macro avg       0.77      0.88      0.81     31893
weighted avg       0.97      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     31632
           1       0.18      0.69      0.29       261

    accuracy                           0.97     31893
   macro avg       0.59      0.83      0.64     31893
weighted avg       0.99      0.97      0.98     31893






GloVe embeddings
        200 trees
        class_weight='balanced',
        min_samples_leaf=2,
        min_samples_split=20,
        no depth limit




Found 164223 unique tokens.
Loading GloVe: 38054it [00:00, 41275.29it/s]
Loaded 38054 word vectors from GloVe.

Training Random Forest for label: toxic
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28834
           1       0.80      0.56      0.66      3059

    accuracy                           0.94     31893
   macro avg       0.88      0.77      0.81     31893
weighted avg       0.94      0.94      0.94     31893


Training Random Forest for label: severe_toxic
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     31608
           1       0.44      0.38      0.41       285

    accuracy                           0.99     31893
   macro avg       0.72      0.69      0.70     31893
weighted avg       0.99      0.99      0.99     31893


Training Random Forest for label: obscene
              precision    recall  f1-score   support

           0       0.98      0.99      0.98     30199
           1       0.80      0.56      0.66      1694

    accuracy                           0.97     31893
   macro avg       0.89      0.78      0.82     31893
weighted avg       0.97      0.97      0.97     31893


Training Random Forest for label: threat
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.56      0.15      0.23        95

    accuracy                           1.00     31893
   macro avg       0.78      0.57      0.62     31893
weighted avg       1.00      1.00      1.00     31893


Training Random Forest for label: insult
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30324
           1       0.71      0.51      0.59      1569

    accuracy                           0.97     31893
   macro avg       0.84      0.75      0.79     31893
weighted avg       0.96      0.97      0.96     31893


Training Random Forest for label: identity_hate
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     31632
           1       0.46      0.20      0.28       261

    accuracy                           0.99     31893
   macro avg       0.73      0.60      0.64     31893
weighted avg       0.99      0.99      0.99     31893


Training Random Forest for overall toxic vs non-toxic

Classification report for label: any_toxic
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28650
           1       0.81      0.56      0.66      3243

    accuracy                           0.94     31893
   macro avg       0.88      0.77      0.81     31893
weighted avg       0.94      0.94      0.94     31893
