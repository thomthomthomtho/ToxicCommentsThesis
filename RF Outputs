(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 500000
Matrix shape: (127570, 50000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28650
           1       0.88      0.57      0.69      3243

    accuracy                           0.95     31893
   macro avg       0.92      0.78      0.83     31893
weighted avg       0.95      0.95      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28834
           1       0.86      0.56      0.68      3059

    accuracy                           0.95     31893
   macro avg       0.91      0.78      0.82     31893
weighted avg       0.95      0.95      0.94     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     31608
           1       0.24      0.16      0.20       285

    accuracy                           0.99     31893
   macro avg       0.62      0.58      0.60     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     30199
           1       0.90      0.59      0.71      1694

    accuracy                           0.97     31893
   macro avg       0.94      0.79      0.85     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.54      0.07      0.13        95

    accuracy                           1.00     31893
   macro avg       0.77      0.54      0.56     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30324
           1       0.80      0.48      0.60      1569

    accuracy                           0.97     31893
   macro avg       0.88      0.74      0.79     31893
weighted avg       0.96      0.97      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.08      0.09      0.09       261

    accuracy                           0.98     31893
   macro avg       0.54      0.54      0.54     31893
weighted avg       0.99      0.98      0.98     31893

(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 500000
Matrix shape: (127570, 500000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.94      0.99      0.97     28650
           1       0.86      0.48      0.61      3243

    accuracy                           0.94     31893
   macro avg       0.90      0.73      0.79     31893
weighted avg       0.94      0.94      0.93     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28834
           1       0.84      0.48      0.61      3059

    accuracy                           0.94     31893
   macro avg       0.89      0.73      0.79     31893
weighted avg       0.94      0.94      0.93     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     31608
           1       0.45      0.13      0.21       285

    accuracy                           0.99     31893
   macro avg       0.72      0.57      0.60     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30199
           1       0.78      0.50      0.61      1694

    accuracy                           0.97     31893
   macro avg       0.88      0.75      0.80     31893
weighted avg       0.96      0.97      0.96     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.57      0.08      0.15        95

    accuracy                           1.00     31893
   macro avg       0.78      0.54      0.57     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30324
           1       0.71      0.37      0.49      1569

    accuracy                           0.96     31893
   macro avg       0.84      0.68      0.73     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.08      0.07      0.08       261

    accuracy                           0.99     31893
   macro avg       0.54      0.53      0.53     31893
weighted avg       0.98      0.99      0.99     31893
