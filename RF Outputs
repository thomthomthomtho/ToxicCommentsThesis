best max Depth = no limiet
Best vocab size = 5000
Aantal trees = tussen 100 en 300 presteert evengoed soortvan
Best min_samples_leaf=2
Best min_samples_split=20

(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 50000
Matrix shape: (127570, 50000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 2

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28650
           1       0.88      0.57      0.69      3243

    accuracy                           0.95     31893
   macro avg       0.92      0.78      0.83     31893
weighted avg       0.95      0.95      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28834
           1       0.86      0.56      0.68      3059

    accuracy                           0.95     31893
   macro avg       0.91      0.78      0.82     31893
weighted avg       0.95      0.95      0.94     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     31608
           1       0.24      0.16      0.20       285

    accuracy                           0.99     31893
   macro avg       0.62      0.58      0.60     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     30199
           1       0.90      0.59      0.71      1694

    accuracy                           0.97     31893
   macro avg       0.94      0.79      0.85     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.54      0.07      0.13        95

    accuracy                           1.00     31893
   macro avg       0.77      0.54      0.56     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30324
           1       0.80      0.48      0.60      1569

    accuracy                           0.97     31893
   macro avg       0.88      0.74      0.79     31893
weighted avg       0.96      0.97      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.08      0.09      0.09       261

    accuracy                           0.98     31893
   macro avg       0.54      0.54      0.54     31893
weighted avg       0.99      0.98      0.98     31893

(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 500000
Matrix shape: (127570, 500000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 2

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.94      0.99      0.97     28650
           1       0.86      0.48      0.61      3243

    accuracy                           0.94     31893
   macro avg       0.90      0.73      0.79     31893
weighted avg       0.94      0.94      0.93     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.95      0.99      0.97     28834
           1       0.84      0.48      0.61      3059

    accuracy                           0.94     31893
   macro avg       0.89      0.73      0.79     31893
weighted avg       0.94      0.94      0.93     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     31608
           1       0.45      0.13      0.21       285

    accuracy                           0.99     31893
   macro avg       0.72      0.57      0.60     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30199
           1       0.78      0.50      0.61      1694

    accuracy                           0.97     31893
   macro avg       0.88      0.75      0.80     31893
weighted avg       0.96      0.97      0.96     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.57      0.08      0.15        95

    accuracy                           1.00     31893
   macro avg       0.78      0.54      0.57     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     30324
           1       0.71      0.37      0.49      1569

    accuracy                           0.96     31893
   macro avg       0.84      0.68      0.73     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.08      0.07      0.08       261

    accuracy                           0.99     31893
   macro avg       0.54      0.53      0.53     31893
weighted avg       0.98      0.99      0.99     31893


(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 300
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 2

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.96      0.98      0.97     28650
           1       0.80      0.66      0.72      3243

    accuracy                           0.95     31893
   macro avg       0.88      0.82      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.96      0.98      0.97     28834
           1       0.78      0.65      0.71      3059

    accuracy                           0.95     31893
   macro avg       0.87      0.82      0.84     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     31608
           1       0.36      0.25      0.30       285

    accuracy                           0.99     31893
   macro avg       0.68      0.62      0.64     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.99      0.98     30199
           1       0.74      0.72      0.73      1694

    accuracy                           0.97     31893
   macro avg       0.86      0.85      0.86     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.44      0.08      0.14        95

    accuracy                           1.00     31893
   macro avg       0.72      0.54      0.57     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     30324
           1       0.62      0.60      0.61      1569

    accuracy                           0.96     31893
   macro avg       0.80      0.79      0.80     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.16      0.18      0.17       261

    accuracy                           0.99     31893
   macro avg       0.57      0.59      0.58     31893
weighted avg       0.99      0.99      0.99     31893



(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 2

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.96      0.98      0.97     28650
           1       0.79      0.66      0.72      3243

    accuracy                           0.95     31893
   macro avg       0.88      0.82      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.96      0.98      0.97     28834
           1       0.78      0.64      0.70      3059

    accuracy                           0.95     31893
   macro avg       0.87      0.81      0.84     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     31608
           1       0.35      0.24      0.28       285

    accuracy                           0.99     31893
   macro avg       0.67      0.62      0.64     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.99      0.98     30199
           1       0.73      0.71      0.72      1694

    accuracy                           0.97     31893
   macro avg       0.86      0.85      0.85     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.47      0.08      0.14        95

    accuracy                           1.00     31893
   macro avg       0.73      0.54      0.57     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     30324
           1       0.62      0.60      0.61      1569

    accuracy                           0.96     31893
   macro avg       0.80      0.79      0.80     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.15      0.19      0.17       261

    accuracy                           0.98     31893
   macro avg       0.57      0.59      0.58     31893
weighted avg       0.99      0.98      0.99     31893


(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 10

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28650
           1       0.74      0.71      0.72      3243

    accuracy                           0.95     31893
   macro avg       0.85      0.84      0.85     31893
weighted avg       0.94      0.95      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28834
           1       0.72      0.69      0.71      3059

    accuracy                           0.95     31893
   macro avg       0.85      0.83      0.84     31893
weighted avg       0.94      0.95      0.94     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31608
           1       0.30      0.39      0.34       285

    accuracy                           0.99     31893
   macro avg       0.65      0.69      0.67     31893
weighted avg       0.99      0.99      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     30199
           1       0.70      0.78      0.74      1694

    accuracy                           0.97     31893
   macro avg       0.84      0.88      0.86     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.31      0.18      0.23        95

    accuracy                           1.00     31893
   macro avg       0.66      0.59      0.61     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.97      0.98     30324
           1       0.59      0.70      0.64      1569

    accuracy                           0.96     31893
   macro avg       0.78      0.84      0.81     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31632
           1       0.21      0.34      0.26       261

    accuracy                           0.98     31893
   macro avg       0.60      0.67      0.63     31893
weighted avg       0.99      0.98      0.99     31893


(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 1
min_sample_split = 20


 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28650
           1       0.73      0.72      0.72      3243

    accuracy                           0.94     31893
   macro avg       0.85      0.84      0.85     31893
weighted avg       0.94      0.94      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28834
           1       0.71      0.71      0.71      3059

    accuracy                           0.94     31893
   macro avg       0.84      0.84      0.84     31893
weighted avg       0.94      0.94      0.94     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     31608
           1       0.27      0.42      0.33       285

    accuracy                           0.98     31893
   macro avg       0.63      0.71      0.66     31893
weighted avg       0.99      0.98      0.99     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     30199
           1       0.68      0.79      0.73      1694

    accuracy                           0.97     31893
   macro avg       0.83      0.89      0.86     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.34      0.22      0.27        95

    accuracy                           1.00     31893
   macro avg       0.67      0.61      0.63     31893
weighted avg       1.00      1.00      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.98      0.97      0.98     30324
           1       0.57      0.71      0.63      1569

    accuracy                           0.96     31893
   macro avg       0.78      0.84      0.81     31893
weighted avg       0.96      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     31632
           1       0.22      0.41      0.28       261

    accuracy                           0.98     31893
   macro avg       0.61      0.70      0.64     31893
weighted avg       0.99      0.98      0.99     31893



Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 100
class_weight = 'balanced'
min_sample_leaf = 2
min_sample_split = 20

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28650
           1       0.72      0.75      0.73      3243

    accuracy                           0.94     31893
   macro avg       0.84      0.86      0.85     31893
weighted avg       0.95      0.94      0.94     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28834
           1       0.70      0.74      0.72      3059

    accuracy                           0.95     31893
   macro avg       0.84      0.85      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31608
           1       0.22      0.70      0.33       285

    accuracy                           0.97     31893
   macro avg       0.61      0.84      0.66     31893
weighted avg       0.99      0.97      0.98     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.99     30199
           1       0.70      0.83      0.76      1694

    accuracy                           0.97     31893
   macro avg       0.84      0.90      0.87     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.27      0.44      0.34        95

    accuracy                           0.99     31893
   macro avg       0.64      0.72      0.67     31893
weighted avg       1.00      0.99      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.97      0.98     30324
           1       0.57      0.78      0.66      1569

    accuracy                           0.96     31893
   macro avg       0.78      0.87      0.82     31893
weighted avg       0.97      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31632
           1       0.19      0.57      0.29       261

    accuracy                           0.98     31893
   macro avg       0.60      0.77      0.64     31893
weighted avg       0.99      0.98      0.98     31893




(.venv) (base) thomdeveling@MacBook-Air-van-Thom-3 Thesis % "/Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/.venv/bin/python" "/
Users/thomdeveling/Documents/Kunstmatige Intelligentie/Jaar 3/Thesis/Random Forest.py"
Using TfidfVectorizer
Vocab size: 5000
Matrix shape: (127570, 5000)
Random Forest settings:
n_estimators = 300
class_weight = 'balanced'
min_sample_leaf = 2
min_sample_split = 20

 Training Random Forest for label: any_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28650
           1       0.72      0.75      0.74      3243

    accuracy                           0.95     31893
   macro avg       0.85      0.86      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     28834
           1       0.71      0.74      0.72      3059

    accuracy                           0.95     31893
   macro avg       0.84      0.86      0.85     31893
weighted avg       0.95      0.95      0.95     31893


 Training Random Forest for label: severe_toxic (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31608
           1       0.22      0.70      0.34       285

    accuracy                           0.98     31893
   macro avg       0.61      0.84      0.66     31893
weighted avg       0.99      0.98      0.98     31893


 Training Random Forest for label: obscene (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     30199
           1       0.69      0.83      0.75      1694

    accuracy                           0.97     31893
   macro avg       0.84      0.90      0.87     31893
weighted avg       0.97      0.97      0.97     31893


 Training Random Forest for label: threat (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     31798
           1       0.25      0.42      0.31        95

    accuracy                           0.99     31893
   macro avg       0.62      0.71      0.66     31893
weighted avg       1.00      0.99      1.00     31893


 Training Random Forest for label: insult (testset size: 31893)
              precision    recall  f1-score   support

           0       0.99      0.97      0.98     30324
           1       0.58      0.78      0.66      1569

    accuracy                           0.96     31893
   macro avg       0.78      0.87      0.82     31893
weighted avg       0.97      0.96      0.96     31893


 Training Random Forest for label: identity_hate (testset size: 31893)
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     31632
           1       0.20      0.57      0.30       261

    accuracy                           0.98     31893
   macro avg       0.60      0.78      0.64     31893
weighted avg       0.99      0.98      0.98     31893
